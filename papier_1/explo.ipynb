{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from ipywidgets import IntProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pretrained BERT finetuned on IMDB Database\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"fabriceyhc/bert-base-uncased-imdb\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"fabriceyhc/bert-base-uncased-imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/onyxia/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05b3786007c4474b152e1952d7262df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (/home/onyxia/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c6b559d4c74338b193a45180579359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading IMDB dataset (IN) and SST2 (OUT)\n",
    "\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "out_dataset = load_dataset(\"sst2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate train distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hook functions to get latent representation of data\n",
    "\n",
    "def features_hook_0(model, inp, output):\n",
    "    global feat_0\n",
    "    feat_0 = output\n",
    "\n",
    "def features_hook_1(model, inp, output):\n",
    "    global feat_1\n",
    "    feat_1 = output\n",
    "\n",
    "def features_hook_2(model, inp, output):\n",
    "    global feat_2\n",
    "    feat_2 = output\n",
    "\n",
    "def features_hook_3(model, inp, output):\n",
    "    global feat_3\n",
    "    feat_3 = output\n",
    "\n",
    "def features_hook_4(model, inp, output):\n",
    "    global feat_4\n",
    "    feat_4 = output\n",
    "\n",
    "def features_hook_5(model, inp, output):\n",
    "    global feat_5\n",
    "    feat_5 = output\n",
    "\n",
    "def features_hook_6(model, inp, output):\n",
    "    global feat_6\n",
    "    feat_6 = output\n",
    "\n",
    "def features_hook_7(model, inp, output):\n",
    "    global feat_7\n",
    "    feat_7 = output\n",
    "\n",
    "def features_hook_8(model, inp, output):\n",
    "    global feat_8\n",
    "    feat_8 = output\n",
    "\n",
    "def features_hook_9(model, inp, output):\n",
    "    global feat_9\n",
    "    feat_9 = output\n",
    "\n",
    "def features_hook_10(model, inp, output):\n",
    "    global feat_10\n",
    "    feat_10 = output\n",
    "\n",
    "def features_hook_11(model, inp, output):\n",
    "    global feat_11\n",
    "    feat_11 = output\n",
    "\n",
    "features_hooks = [features_hook_0, features_hook_1, features_hook_2, \n",
    "                    features_hook_3, features_hook_4, features_hook_5, \n",
    "                    features_hook_6, features_hook_7, features_hook_8, \n",
    "                    features_hook_9, features_hook_10, features_hook_11]\n",
    "\n",
    "\n",
    "\n",
    "feat_hook = [model.base_model.encoder.layer[i].register_forward_hook(features_hooks[i]) for i in range(12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lattent_representation(input_data, model):\n",
    "    \"\"\"aggregating latent representation to create a unique representation vector\n",
    "    \"\"\"\n",
    "    pipe = TextClassificationPipeline(\n",
    "                                model=model, tokenizer=tokenizer\n",
    "                                )\n",
    "    pipe(input_data)\n",
    "    feats = [feat_0[0], feat_1[0], feat_2[0], \n",
    "                feat_3[0], feat_4[0], feat_5[0], \n",
    "                feat_6[0], feat_7[0], feat_8[0], \n",
    "                feat_9[0], feat_10[0], feat_11[0]]\n",
    "    aggregated_features = torch.mean(torch.stack([i[0, 0, :] for i in feats]), dim= 0)\n",
    "\n",
    "    return aggregated_features\n",
    "\n",
    "###### IF THE DISTRIBUTION IS NOT COMPLETED ######\n",
    "\n",
    "# distrib =[] \n",
    "# fail = []\n",
    "# for i in tqdm(range(len(dataset['train']))):\n",
    "#     if i%100 == 0:\n",
    "#         print(i)\n",
    "#     try:\n",
    "#         distrib.append(get_lattent_representation(dataset['train'][i]['text'], model))\n",
    "#     except:\n",
    "#         fail.append(i)\n",
    "\n",
    "# def process_distrib(distrib):\n",
    "#     return np.vstack([distrib[i].numpy().flatten() for i in range(len(distrib))])\n",
    "\n",
    "# distrib = process_distrib(distrib)\n",
    "# pd.DataFrame(distrib).to_csv('distrib_.csv', index = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### IF THE DISTRIBUTION IS ALREADY COMPLETED ######\n",
    "\n",
    "\n",
    "distrib = np.array(pd.read_csv('distrib_first.csv'))\n",
    "# distrib = distrib[:, 1:]\n",
    "assert distrib.shape[1] == 768 # checking the shape : vectors must have a 768 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits(input_data, model):\n",
    "    pipe = TextClassificationPipeline(\n",
    "                                model=model, tokenizer=tokenizer\n",
    "                                )\n",
    "    res = pipe(input_data)\n",
    "    return res[0]['score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f198fb29254392b2c0a93792e16c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "17\n",
      "34\n",
      "42\n",
      "44\n",
      "52\n",
      "55\n",
      "69\n",
      "74\n",
      "80\n",
      "87\n",
      "92\n",
      "95\n",
      "98\n",
      "100\n",
      "111\n",
      "112\n",
      "128\n",
      "142\n",
      "147\n",
      "149\n",
      "165\n",
      "180\n",
      "197\n",
      "198\n",
      "200\n",
      "209\n",
      "213\n",
      "218\n",
      "230\n",
      "238\n",
      "246\n",
      "248\n",
      "253\n",
      "257\n",
      "264\n",
      "265\n",
      "273\n",
      "281\n",
      "282\n",
      "298\n",
      "300\n",
      "312\n",
      "345\n",
      "353\n",
      "370\n",
      "374\n",
      "375\n",
      "394\n",
      "400\n",
      "413\n",
      "415\n",
      "416\n",
      "421\n",
      "422\n",
      "440\n",
      "457\n",
      "459\n",
      "461\n",
      "478\n",
      "479\n",
      "483\n",
      "498\n",
      "500\n",
      "500\n",
      "501\n",
      "509\n",
      "517\n",
      "520\n",
      "521\n",
      "528\n",
      "531\n",
      "543\n",
      "581\n",
      "591\n",
      "593\n",
      "600\n",
      "603\n",
      "612\n",
      "614\n",
      "615\n",
      "618\n",
      "651\n",
      "652\n",
      "655\n",
      "657\n",
      "661\n",
      "666\n",
      "667\n",
      "668\n",
      "674\n",
      "681\n",
      "687\n",
      "688\n",
      "689\n",
      "700\n",
      "700\n",
      "706\n",
      "725\n",
      "726\n",
      "735\n",
      "736\n",
      "740\n",
      "745\n",
      "746\n",
      "749\n",
      "750\n",
      "751\n",
      "753\n",
      "757\n",
      "759\n",
      "762\n",
      "768\n",
      "771\n",
      "773\n",
      "779\n",
      "784\n",
      "788\n",
      "797\n",
      "800\n",
      "803\n",
      "812\n",
      "814\n",
      "825\n",
      "831\n",
      "832\n",
      "848\n",
      "877\n",
      "878\n",
      "896\n",
      "899\n",
      "900\n",
      "913\n",
      "922\n",
      "926\n",
      "932\n",
      "942\n",
      "958\n",
      "965\n",
      "974\n",
      "982\n",
      "983\n",
      "984\n",
      "989\n",
      "1000\n",
      "1001\n",
      "1019\n",
      "1020\n",
      "1025\n",
      "1026\n",
      "1041\n",
      "1056\n",
      "1075\n",
      "1080\n",
      "1084\n",
      "1090\n",
      "1100\n",
      "1104\n",
      "1107\n",
      "1109\n",
      "1123\n",
      "1127\n",
      "1131\n",
      "1147\n",
      "1167\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1181\n",
      "1197\n",
      "1199\n",
      "1200\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1216\n",
      "1228\n",
      "1233\n",
      "1244\n",
      "1261\n",
      "1263\n",
      "1267\n",
      "1281\n",
      "1282\n",
      "1300\n",
      "1306\n",
      "1330\n",
      "1332\n",
      "1336\n",
      "1340\n",
      "1342\n",
      "1347\n",
      "1361\n",
      "1364\n",
      "1371\n",
      "1391\n",
      "1395\n",
      "1400\n",
      "1400\n",
      "1406\n",
      "1427\n",
      "1432\n",
      "1439\n",
      "1444\n",
      "1445\n",
      "1449\n",
      "1451\n",
      "1452\n",
      "1458\n",
      "1466\n",
      "1469\n",
      "1477\n",
      "1481\n",
      "1492\n",
      "1500\n",
      "1509\n",
      "1514\n",
      "1520\n",
      "1522\n",
      "1531\n",
      "1543\n",
      "1545\n",
      "1561\n",
      "1564\n",
      "1568\n",
      "1572\n",
      "1586\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1600\n",
      "1606\n",
      "1608\n",
      "1622\n",
      "1654\n",
      "1663\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1700\n",
      "1703\n",
      "1713\n",
      "1727\n",
      "1729\n",
      "1745\n",
      "1759\n",
      "1771\n",
      "1773\n",
      "1778\n",
      "1786\n",
      "1787\n",
      "1800\n",
      "1808\n",
      "1809\n",
      "1812\n",
      "1828\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1837\n",
      "1854\n",
      "1874\n",
      "1879\n",
      "1891\n",
      "1894\n",
      "1896\n",
      "1900\n",
      "1900\n",
      "1903\n",
      "1906\n",
      "1907\n",
      "1911\n",
      "1915\n",
      "1919\n",
      "1927\n",
      "1929\n",
      "1938\n",
      "1939\n",
      "1949\n",
      "1966\n",
      "1987\n",
      "1999\n",
      "2000\n",
      "2000\n",
      "2003\n",
      "2013\n",
      "2016\n",
      "2022\n",
      "2025\n",
      "2029\n",
      "2033\n",
      "2035\n",
      "2037\n",
      "2038\n",
      "2040\n",
      "2043\n",
      "2050\n",
      "2057\n",
      "2063\n",
      "2064\n",
      "2071\n",
      "2083\n",
      "2090\n",
      "2100\n",
      "2104\n",
      "2108\n",
      "2113\n",
      "2124\n",
      "2136\n",
      "2140\n",
      "2148\n",
      "2149\n",
      "2156\n",
      "2177\n",
      "2179\n",
      "2188\n",
      "2189\n",
      "2193\n",
      "2199\n",
      "2200\n",
      "2200\n",
      "2201\n",
      "2217\n",
      "2222\n",
      "2226\n",
      "2239\n",
      "2252\n",
      "2262\n",
      "2266\n",
      "2267\n",
      "2271\n",
      "2300\n",
      "2302\n",
      "2305\n",
      "2311\n",
      "2318\n",
      "2322\n",
      "2337\n",
      "2342\n",
      "2361\n",
      "2362\n",
      "2365\n",
      "2373\n",
      "2378\n",
      "2380\n",
      "2392\n",
      "2394\n",
      "2400\n",
      "2406\n",
      "2416\n",
      "2431\n",
      "2456\n",
      "2457\n",
      "2460\n",
      "2467\n",
      "2482\n",
      "2496\n",
      "2500\n",
      "2511\n",
      "2525\n",
      "2532\n",
      "2535\n",
      "2537\n",
      "2539\n",
      "2553\n",
      "2561\n",
      "2586\n",
      "2595\n",
      "2600\n",
      "2633\n",
      "2650\n",
      "2655\n",
      "2658\n",
      "2666\n",
      "2671\n",
      "2679\n",
      "2686\n",
      "2700\n",
      "2711\n",
      "2712\n",
      "2717\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2763\n",
      "2773\n",
      "2779\n",
      "2783\n",
      "2787\n",
      "2796\n",
      "2799\n",
      "2800\n",
      "2806\n",
      "2808\n",
      "2815\n",
      "2818\n",
      "2821\n",
      "2824\n",
      "2828\n",
      "2831\n",
      "2841\n",
      "2842\n",
      "2853\n",
      "2865\n",
      "2882\n",
      "2900\n",
      "2903\n",
      "2931\n",
      "2933\n",
      "2955\n",
      "2963\n",
      "2964\n",
      "2980\n",
      "2987\n",
      "2994\n",
      "2995\n",
      "2997\n",
      "3000\n",
      "3009\n",
      "3013\n",
      "3021\n",
      "3023\n",
      "3024\n",
      "3026\n",
      "3029\n",
      "3030\n",
      "3032\n",
      "3033\n",
      "3034\n",
      "3035\n",
      "3038\n",
      "3048\n",
      "3063\n",
      "3073\n",
      "3074\n",
      "3076\n",
      "3100\n",
      "3101\n",
      "3124\n",
      "3128\n",
      "3129\n",
      "3131\n",
      "3140\n",
      "3147\n",
      "3165\n",
      "3170\n",
      "3174\n",
      "3178\n",
      "3183\n",
      "3200\n",
      "3201\n",
      "3207\n",
      "3233\n",
      "3239\n",
      "3260\n",
      "3261\n",
      "3265\n",
      "3266\n",
      "3271\n",
      "3277\n",
      "3278\n",
      "3279\n",
      "3280\n",
      "3282\n",
      "3291\n",
      "3292\n",
      "3300\n",
      "3311\n",
      "3314\n",
      "3321\n",
      "3322\n",
      "3324\n",
      "3327\n",
      "3339\n",
      "3365\n"
     ]
    }
   ],
   "source": [
    "def get_lattent_last_layer(input_data, model):\n",
    "    pipe = TextClassificationPipeline(\n",
    "                            model=model, tokenizer=tokenizer\n",
    "                                )\n",
    "    pipe(input_data)\n",
    "    feat = feat_11[0]\n",
    "\n",
    "    return feat[0][0]\n",
    "\n",
    "###### IF THE DISTRIBUTION IS NOT COMPLETED ######\n",
    "\n",
    "distrib_last_layer = [] \n",
    "fail = []\n",
    "for i in tqdm(range(len(dataset['train']))):\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "    try:\n",
    "        distrib_last_layer.append(get_lattent_last_layer(dataset['train'][i]['text'], model))\n",
    "    except:\n",
    "        print(i)\n",
    "        fail.append(i)\n",
    "\n",
    "def process_distrib(distrib):\n",
    "    return np.vstack([distrib[i].numpy().flatten() for i in range(len(distrib))])\n",
    "\n",
    "distrib_last_layer = process_distrib(distrib_last_layer)\n",
    "pd.DataFrame(distrib_last_layer).to_csv('distrib_last_layer.csv', index = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### IF THE DISTRIBUTION IS ALREADY COMPLETED ######\n",
    "\n",
    "\n",
    "distrib_last_layer = np.array(pd.read_csv('distrib_last_layer.csv'))\n",
    "# distrib = distrib[:, 1:]\n",
    "assert distrib.shape[1] == 768 # checking the shape : vectors must have a 768 size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing variables for Mahalanobis score\n",
    "\n",
    "cov_matrix = np.cov(distrib.T)\n",
    "precision_matrix = np.linalg.inv(cov_matrix)\n",
    "esperance_vector = np.mean(distrib, axis = 0)\n",
    "\n",
    "def D_M(x, esperance = esperance, precision = precision_mat):\n",
    "    \"\"\"Mahalanobis distance\n",
    "    \"\"\"\n",
    "    v = x - esperance\n",
    "    u = 1 + (v.T @ precision @ v)\n",
    "    return -1 / u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSP(x):\n",
    "    \"\"\"Max softmax proba\n",
    "    x is the max logits value\n",
    "    \"\"\"\n",
    "    return 1 - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last layer mahalanobis score\n",
    "\n",
    "cov_matrix = np.cov(distrib.T)\n",
    "precision_matrix = np.linalg.inv(cov_matrix)\n",
    "esperance_vector = np.mean(distrib, axis = 0)\n",
    "\n",
    "def D_M(x, esperance = esperance, precision = precision_mat):\n",
    "    \"\"\"Mahalanobis distance\n",
    "    \"\"\"\n",
    "    v = x - esperance\n",
    "    u = 1 + (v.T @ precision @ v)\n",
    "    return -1 / u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing In and Out distances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = min([len(out_dataset['test']), len(dataset['test'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85afa14a74e469992f23aa94e0ac9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07b4860914a401e844823634359d51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = {\n",
    "            'maha' : {'in' : [], 'out' : []},\n",
    "            'MSP' : {'in' : [], 'out' : []},\n",
    "            }\n",
    "\n",
    "for i in tqdm(range(N)):\n",
    "    input_data = out_dataset['test'][i]['sentence']\n",
    "\n",
    "    x = get_lattent_representation(input_data, model)\n",
    "    distances['maha']['out'].append(D_M(x.numpy()))\n",
    "\n",
    "    logit = get_logits(input_data, model)\n",
    "    distances['MSP']['out'].append(MSP(logit))\n",
    "\n",
    "for i in tqdm(range(N)):\n",
    "    try:\n",
    "        input_data = dataset['test'][i]['text']\n",
    "\n",
    "        x = get_lattent_representation(input_data, model)\n",
    "        distances['maha']['in'].append(D_M(x.numpy()))\n",
    "\n",
    "        logit = get_logits(input_data, model)\n",
    "        distances['MSP']['in'].append(MSP(logit))\n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "color=out<br>value=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "out",
         "marker": {
          "color": "#1F77B4",
          "pattern": {
           "shape": ""
          }
         },
         "name": "out",
         "offsetgroup": "out",
         "orientation": "v",
         "showlegend": true,
         "type": "histogram",
         "x": [
          0.0013039708137512207,
          0.0042549967765808105,
          0.0011394023895263672,
          0.0005292296409606934,
          0.00042182207107543945,
          0.0003712177276611328,
          0.009854257106781006,
          0.00037276744842529297,
          0.003856062889099121,
          0.003152787685394287
         ],
         "xaxis": "x",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "color=in<br>value=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "in",
         "marker": {
          "color": "#FF7F0E",
          "pattern": {
           "shape": ""
          }
         },
         "name": "in",
         "offsetgroup": "in",
         "orientation": "v",
         "showlegend": true,
         "type": "histogram",
         "x": [
          0.0004698038101196289,
          0.0041002631187438965,
          0.00047969818115234375,
          0.00046837329864501953,
          0.00033342838287353516,
          0.0003967881202697754,
          0.004540622234344482,
          0.0004457831382751465,
          0.0005704760551452637,
          0.0003427267074584961
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "color"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "scatter": [
           {
            "type": "scatter"
           }
          ]
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"baad6c25-ad2d-4c9f-a827-ebb2b0e1103d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"baad6c25-ad2d-4c9f-a827-ebb2b0e1103d\")) {                    Plotly.newPlot(                        \"baad6c25-ad2d-4c9f-a827-ebb2b0e1103d\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"color=out<br>value=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"out\",\"marker\":{\"color\":\"#1F77B4\",\"pattern\":{\"shape\":\"\"}},\"name\":\"out\",\"offsetgroup\":\"out\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.0013039708137512207,0.0042549967765808105,0.0011394023895263672,0.0005292296409606934,0.00042182207107543945,0.0003712177276611328,0.009854257106781006,0.00037276744842529297,0.003856062889099121,0.003152787685394287],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"},{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"color=in<br>value=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"in\",\"marker\":{\"color\":\"#FF7F0E\",\"pattern\":{\"shape\":\"\"}},\"name\":\"in\",\"offsetgroup\":\"in\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.0004698038101196289,0.0041002631187438965,0.00047969818115234375,0.00046837329864501953,0.00033342838287353516,0.0003967881202697754,0.004540622234344482,0.0004457831382751465,0.0005704760551452637,0.0003427267074584961],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"scatter\":[{\"type\":\"scatter\"}]}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"title\":{\"text\":\"color\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('baad6c25-ad2d-4c9f-a827-ebb2b0e1103d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.histogram(\n",
    "            distances['maha']['out'] + distances['maha']['in'], \n",
    "            color = ['out'] * len(distances['maha']['out']) + ['in'] * len(distances['maha']['in']), \n",
    "            template = 'none'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(in_distances, out_distances, threshold):\n",
    "    v = np.sum([i >= threshold for i in in_distances]) + np.sum([i < threshold for i in out_distances])\n",
    "    return v / (len(out_distances) + len(in_distances))\n",
    "\n",
    "def compute_best_threshold(in_distances, out_distances, n_candidates = 1000):\n",
    "\n",
    "    candidates = np.linspace(min(in_distances), max(out_distances), n_candidates)\n",
    "\n",
    "    errors = [error(in_distances, out_distances, i) for i in candidates]\n",
    "    best_index = np.argmin(errors)\n",
    "    return (candidates[best_index], errors[best_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0008962058910801728, 0.0)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_best_threshold(distances['maha']['in'], distances['maha']['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0004859141282013825, 0.3)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_best_threshold(distances['MSP']['in'], distances['MSP']['out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sphere_point(ndim):\n",
    "    vec = np.random.randn(ndim)\n",
    "    vec /= np.linalg.norm(vec, axis=0)\n",
    "    return vec\n",
    "\n",
    "def compute_minimum_value(x, distrib, u_k):\n",
    "    positive_rate = np.mean(np.array([np.dot(u_k, distrib[i] - x) for i in range(len(distrib))]) > 0)\n",
    "    return min(positive_rate, 1 - positive_rate)\n",
    "\n",
    "def D(x, distrib, n_proj = 10):\n",
    "    u = [generate_sphere_point(x.shape[0]) for _ in range(n_proj)]\n",
    "    vector_of_minimums = [compute_minimum_value(x, distrib, u_k) for u_k in u]\n",
    "    return np.mean(vector_of_minimums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_(x, distrib, n_proj = 100):\n",
    "    u = [generate_sphere_point(x.shape[0]) for _ in range(n_proj)]\n",
    "    vector_of_minimums = [compute_minimum_value(x, distrib, u_k) for u_k in u]\n",
    "    return (vector_of_minimums)\n",
    "\n",
    "x = np.random.random(distrib[0].shape)\n",
    "a = D_(x, distrib, 1000)\n",
    "\n",
    "px.line([np.mean(a[:i]) for i in range(1, len(a))], template = 'none')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6670ed0e86a30fbcc29efc36418bab4334369c7a9631e4b406913d45ea19334a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
